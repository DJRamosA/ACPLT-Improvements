{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\dra98\\OneDrive\\Documentos\\Trabajo\\Doctorado\\Codigo\\myvenv\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "import time\n",
    "from scipy.stats import mode\n",
    "import sys\n",
    "import os\n",
    "import csv\n",
    "\n",
    "sys.path.append(os.path.join(\"..\", \"..\"))\n",
    "\n",
    "# Word Embedding\n",
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "random.seed(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from hydra import initialize, compose\n",
    "\n",
    "with initialize(version_base=None, config_path=\"../../conf\"):\n",
    "    cfg=compose(config_name=\"main.yaml\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_labels(matrix, classes):\n",
    "    topks = np.argsort(matrix, axis=1)[:,::-1][:,:5]\n",
    "    \n",
    "    return classes[topks]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LaBSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Execution time: 791.429123878479\n"
     ]
    }
   ],
   "source": [
    "import gensim\n",
    "import spacy\n",
    "from functions.Vectorize import to_vector\n",
    "\n",
    "\n",
    "# Data import\n",
    "# Relative Path of the dataset, change for your dataset\n",
    "dataset_name = \"cpn120\"\n",
    "# Options are \"cpn27\" and \"cpn120\"\n",
    "\n",
    "type_standardization = \"lemmatize\"\n",
    "# options are \"raw\", \"normalize\", \"normalize_wo_stop\", \"lemmatize\", and \"lemmatize_wo_stop\"\n",
    "\n",
    "# import of the data\n",
    "data = pd.read_csv(cfg.path[type_standardization][dataset_name], delimiter=\",\")\n",
    "data = data.fillna(value='')\n",
    "\n",
    "# Import of the model\n",
    "model = SentenceTransformer('sentence-transformers/LaBSE')\n",
    "\n",
    "\n",
    "\n",
    "# Embedding matrix\n",
    "\n",
    "start = time.time()\n",
    "\n",
    "# Creation of a matrix full of 0 to save the vectors of each feature\n",
    "descriptions_matrix = np.zeros( # creatign an empty matrix\n",
    "    (\n",
    "        len(data),          # the number of data points\n",
    "        cfg.params.vector_length.sentence_embedding       # the number of components of the word embedding\n",
    "    )\n",
    ")\n",
    "\n",
    "# Change to the name of the descriptions of your dataset.\n",
    "for i,description in enumerate(data.iloc[:,1]):\n",
    "    vector = model.encode(description)\n",
    "    descriptions_matrix[i,] = vector\n",
    "\n",
    "# Concatenate the matrix with the data of each observation\n",
    "data_matrix = np.concatenate([descriptions_matrix,data], axis=1)\n",
    "\n",
    "# Remove of the 'Nan' data\n",
    "data_matrix = data_matrix[~pd.isnull(data_matrix[:,:cfg.params.vector_length.sentence_embedding]).any(axis=1)]\n",
    "\n",
    "end = time.time()\n",
    "print(\"Execution time:\", end-start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "name_file = f\"../../../data/experiment-top5/experiment_2/resultados_exp_2_{dataset_name}_labse_lemma_top5.csv\"\n",
    "\n",
    "fields = [\"model\",\"mean_acc_top1\",\"std_top1\",\"mean_acc_top3\",\"std_top3\",\"mean_acc_top5\",\"std_top5\",\"E-type\"]\n",
    "\n",
    "if not os.path.isfile(name_file):\n",
    "    with open(name_file, 'w', newline='') as f:\n",
    "        csvwriter = csv.DictWriter(f, fieldnames = fields)\n",
    "        csvwriter.writeheader() \n",
    "        f.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classification Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Original"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\dra98\\OneDrive\\Documentos\\Trabajo\\Doctorado\\Codigo\\myvenv\\lib\\site-packages\\sklearn\\model_selection\\_split.py:700: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=5.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.59360095 0.64823158 0.67140036]\n",
      "[0.54321535 0.6106267  0.63811853]\n"
     ]
    }
   ],
   "source": [
    "# Classification Model\n",
    "from functions.AC_PLT import AC_PLT\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "\n",
    "accuracies_tops_test = np.zeros((5,3))\n",
    "accuracies_tops_train = np.zeros((5,3))\n",
    "tops = (1, 3, 5)\n",
    "\n",
    "\n",
    "cross_validation = StratifiedKFold(n_splits = 5)\n",
    "\n",
    "X = data_matrix[:, :cfg.params.vector_length.sentence_embedding] \n",
    "y = data_matrix[:, cfg.params.vector_length.sentence_embedding+2]\n",
    "\n",
    "temp_test_acc = np.zeros(5)\n",
    "\n",
    "for c, (train_index, test_index) in enumerate(cross_validation.split(X, y)):\n",
    "\n",
    "    X_train = X[train_index, :]\n",
    "    y_train = y[train_index]\n",
    "\n",
    "    X_test = X[test_index, :]\n",
    "    y_test = y[test_index]\n",
    "    \n",
    "    ## MODIFICAR ESTE HIPERPARAMETRO\n",
    "    classification_model = AC_PLT(n_clusters=cfg.params.kmeans.n_cluster[dataset_name])\n",
    "\n",
    "    classification_model.fit(X_train, y_train)\n",
    "\n",
    "    pred_ranking_test = classification_model.suggestions(X_test, n_codes=5)\n",
    "    pred_ranking_train = classification_model.suggestions(X_train, n_codes=5)\n",
    "\n",
    "    top1_acc_test = np.zeros(len(y_test))\n",
    "    top3_acc_test = np.zeros(len(y_test))\n",
    "    top5_acc_test = np.zeros(len(y_test))\n",
    "\n",
    "    \n",
    "    for j in range(len(y_test)):\n",
    "        top1_acc_test[j] = int(y_test[j] in pred_ranking_test[j, :tops[0]])\n",
    "        top3_acc_test[j] = int(y_test[j] in pred_ranking_test[j, :tops[1]])\n",
    "        top5_acc_test[j] = int(y_test[j] in pred_ranking_test[j, :tops[2]])\n",
    "\n",
    "\n",
    "    accuracies_tops_test[c] = [np.mean(top1_acc_test), np.mean(top3_acc_test), np.mean(top5_acc_test)]\n",
    "\n",
    "\n",
    "\n",
    "    top1_acc_train = np.zeros(len(y_train))\n",
    "    top3_acc_train = np.zeros(len(y_train))\n",
    "    top5_acc_train = np.zeros(len(y_train))\n",
    "\n",
    "    \n",
    "    for j in range(len(y_train)):\n",
    "        top1_acc_train[j] = int(y_train[j] in pred_ranking_train[j, :tops[0]])\n",
    "        top3_acc_train[j] = int(y_train[j] in pred_ranking_train[j, :tops[1]])\n",
    "        top5_acc_train[j] = int(y_train[j] in pred_ranking_train[j, :tops[2]])\n",
    "    \n",
    "    accuracies_tops_train[c] = [np.mean(top1_acc_train), np.mean(top3_acc_train), np.mean(top5_acc_train)]\n",
    "\n",
    "\n",
    "train_mean = accuracies_tops_train.mean(axis=0)\n",
    "train_std = accuracies_tops_train.std(axis=0)\n",
    "\n",
    "row_train = [classification_model.__class__.__name__, \n",
    "            train_mean[0], train_std[0],\n",
    "            train_mean[1], train_std[1],\n",
    "            train_mean[2], train_std[2],\n",
    "            \"Train\"\n",
    "            ]\n",
    "\n",
    "test_mean = accuracies_tops_test.mean(axis=0)\n",
    "test_std = accuracies_tops_test.std(axis=0)\n",
    "\n",
    "row_test = [classification_model.__class__.__name__, \n",
    "            test_mean[0], test_std[0],\n",
    "            test_mean[1], test_std[1],\n",
    "            test_mean[2], test_std[2],\n",
    "            \"Test\"\n",
    "            ]\n",
    "\n",
    "with open(name_file, 'a', newline='') as f:\n",
    "    csvwriter = csv.writer(f)\n",
    "    csvwriter.writerow(row_train)\n",
    "    csvwriter.writerow(row_test)\n",
    "    f.close()\n",
    "\n",
    "\n",
    "print(accuracies_tops_train.mean(axis=0))\n",
    "print(accuracies_tops_test.mean(axis=0))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Na√Øve Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\dra98\\OneDrive\\Documentos\\Trabajo\\Doctorado\\Codigo\\myvenv\\lib\\site-packages\\sklearn\\model_selection\\_split.py:700: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=5.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.59459737 0.75492723 0.80463062]\n",
      "[0.53401977 0.68632322 0.73616009]\n"
     ]
    }
   ],
   "source": [
    "# Classification Model\n",
    "from functions.AC_PLT import AC_PLT\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "\n",
    "\n",
    "accuracies_tops_test = np.zeros((5,3))\n",
    "accuracies_tops_train = np.zeros((5,3))\n",
    "tops = (1, 3, 5)\n",
    "\n",
    "\n",
    "cross_validation = StratifiedKFold(n_splits = 5)\n",
    "\n",
    "X = data_matrix[:, :cfg.params.vector_length.sentence_embedding] \n",
    "y = data_matrix[:, cfg.params.vector_length.sentence_embedding+2]\n",
    "\n",
    "\n",
    "temp_test_acc = np.zeros(5)\n",
    "\n",
    "\n",
    "for c, (train_index, test_index) in enumerate(cross_validation.split(X, y)):\n",
    "\n",
    "    X_train = X[train_index, :]\n",
    "    y_train = y[train_index]\n",
    "\n",
    "    X_test = X[test_index, :]\n",
    "    y_test = y[test_index]\n",
    "\n",
    "\n",
    "    classification_model = GaussianNB(var_smoothing=50)\n",
    "\n",
    "    classification_model.fit(X_train, y_train)\n",
    "    pred = classification_model.predict_proba(X_test)\n",
    "\n",
    "    pred_ranking_test = set_labels(classification_model.predict_proba(X_test), classification_model.classes_)\n",
    "    pred_ranking_train = set_labels(classification_model.predict_proba(X_train), classification_model.classes_)\n",
    "    \n",
    "    top1_acc_test = np.zeros(len(y_test))\n",
    "    top3_acc_test = np.zeros(len(y_test))\n",
    "    top5_acc_test = np.zeros(len(y_test))\n",
    "\n",
    "    \n",
    "    for j in range(len(y_test)):\n",
    "        top1_acc_test[j] = int(y_test[j] in pred_ranking_test[j, :tops[0]])\n",
    "        top3_acc_test[j] = int(y_test[j] in pred_ranking_test[j, :tops[1]])\n",
    "        top5_acc_test[j] = int(y_test[j] in pred_ranking_test[j, :tops[2]])\n",
    "\n",
    "\n",
    "    accuracies_tops_test[c] = [np.mean(top1_acc_test), np.mean(top3_acc_test), np.mean(top5_acc_test)]\n",
    "\n",
    "\n",
    "\n",
    "    top1_acc_train = np.zeros(len(y_train))\n",
    "    top3_acc_train = np.zeros(len(y_train))\n",
    "    top5_acc_train = np.zeros(len(y_train))\n",
    "\n",
    "    \n",
    "    for j in range(len(y_train)):\n",
    "        top1_acc_train[j] = int(y_train[j] in pred_ranking_train[j, :tops[0]])\n",
    "        top3_acc_train[j] = int(y_train[j] in pred_ranking_train[j, :tops[1]])\n",
    "        top5_acc_train[j] = int(y_train[j] in pred_ranking_train[j, :tops[2]])\n",
    "    \n",
    "    accuracies_tops_train[c] = [np.mean(top1_acc_train), np.mean(top3_acc_train), np.mean(top5_acc_train)]\n",
    "    \n",
    "    # break\n",
    "\n",
    "print(accuracies_tops_train.mean(axis=0))\n",
    "print(accuracies_tops_test.mean(axis=0))\n",
    "\n",
    "train_mean = accuracies_tops_train.mean(axis=0)\n",
    "train_std = accuracies_tops_train.std(axis=0)\n",
    "\n",
    "row_train = [classification_model.__class__.__name__, \n",
    "            train_mean[0], train_std[0],\n",
    "            train_mean[1], train_std[1],\n",
    "            train_mean[2], train_std[2],\n",
    "            \"Train\"\n",
    "            ]\n",
    "\n",
    "test_mean = accuracies_tops_test.mean(axis=0)\n",
    "test_std = accuracies_tops_test.std(axis=0)\n",
    "\n",
    "row_test = [classification_model.__class__.__name__, \n",
    "            test_mean[0], test_std[0],\n",
    "            test_mean[1], test_std[1],\n",
    "            test_mean[2], test_std[2],\n",
    "            \"Test\"\n",
    "            ]\n",
    "\n",
    "with open(name_file, 'a', newline='') as f:\n",
    "    csvwriter = csv.writer(f)\n",
    "    csvwriter.writerow(row_train)\n",
    "    csvwriter.writerow(row_test)\n",
    "    f.close()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\dra98\\OneDrive\\Documentos\\Trabajo\\Doctorado\\Codigo\\myvenv\\lib\\site-packages\\sklearn\\model_selection\\_split.py:700: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=5.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.66047892 0.88719245 0.95087719]\n",
      "[0.60249839 0.7601999  0.79610244]\n"
     ]
    }
   ],
   "source": [
    "# Classification Model\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "\n",
    "\n",
    "accuracies_tops_test = np.zeros((5,3))\n",
    "accuracies_tops_train = np.zeros((5,3))\n",
    "tops = (1, 3, 5)\n",
    "\n",
    "\n",
    "cross_validation = StratifiedKFold(n_splits = 5)\n",
    "\n",
    "X = data_matrix[:, :cfg.params.vector_length.sentence_embedding] \n",
    "y = data_matrix[:, cfg.params.vector_length.sentence_embedding+2]\n",
    "\n",
    "\n",
    "temp_test_acc = np.zeros(5)\n",
    "\n",
    "\n",
    "for c, (train_index, test_index) in enumerate(cross_validation.split(X, y)):\n",
    "\n",
    "    X_train = X[train_index, :]\n",
    "    y_train = y[train_index]\n",
    "\n",
    "    X_test = X[test_index, :]\n",
    "    y_test = y[test_index]\n",
    "\n",
    "\n",
    "    classification_model = KNeighborsClassifier(n_neighbors = 10)\n",
    "\n",
    "    classification_model.fit(X_train, y_train)\n",
    "    pred = classification_model.predict_proba(X_test)\n",
    "\n",
    "    pred_ranking_test = set_labels(classification_model.predict_proba(X_test), classification_model.classes_)\n",
    "    pred_ranking_train = set_labels(classification_model.predict_proba(X_train), classification_model.classes_)\n",
    "    \n",
    "    top1_acc_test = np.zeros(len(y_test))\n",
    "    top3_acc_test = np.zeros(len(y_test))\n",
    "    top5_acc_test = np.zeros(len(y_test))\n",
    "\n",
    "    \n",
    "    for j in range(len(y_test)):\n",
    "        top1_acc_test[j] = int(y_test[j] in pred_ranking_test[j, :tops[0]])\n",
    "        top3_acc_test[j] = int(y_test[j] in pred_ranking_test[j, :tops[1]])\n",
    "        top5_acc_test[j] = int(y_test[j] in pred_ranking_test[j, :tops[2]])\n",
    "\n",
    "\n",
    "    accuracies_tops_test[c] = [np.mean(top1_acc_test), np.mean(top3_acc_test), np.mean(top5_acc_test)]\n",
    "\n",
    "\n",
    "\n",
    "    top1_acc_train = np.zeros(len(y_train))\n",
    "    top3_acc_train = np.zeros(len(y_train))\n",
    "    top5_acc_train = np.zeros(len(y_train))\n",
    "\n",
    "    \n",
    "    for j in range(len(y_train)):\n",
    "        top1_acc_train[j] = int(y_train[j] in pred_ranking_train[j, :tops[0]])\n",
    "        top3_acc_train[j] = int(y_train[j] in pred_ranking_train[j, :tops[1]])\n",
    "        top5_acc_train[j] = int(y_train[j] in pred_ranking_train[j, :tops[2]])\n",
    "    \n",
    "    accuracies_tops_train[c] = [np.mean(top1_acc_train), np.mean(top3_acc_train), np.mean(top5_acc_train)]\n",
    "    \n",
    "    # break\n",
    "\n",
    "print(accuracies_tops_train.mean(axis=0))\n",
    "print(accuracies_tops_test.mean(axis=0))\n",
    "\n",
    "train_mean = accuracies_tops_train.mean(axis=0)\n",
    "train_std = accuracies_tops_train.std(axis=0)\n",
    "\n",
    "row_train = [classification_model.__class__.__name__, \n",
    "            train_mean[0], train_std[0],\n",
    "            train_mean[1], train_std[1],\n",
    "            train_mean[2], train_std[2],\n",
    "            \"Train\"\n",
    "            ]\n",
    "\n",
    "test_mean = accuracies_tops_test.mean(axis=0)\n",
    "test_std = accuracies_tops_test.std(axis=0)\n",
    "\n",
    "row_test = [classification_model.__class__.__name__, \n",
    "            test_mean[0], test_std[0],\n",
    "            test_mean[1], test_std[1],\n",
    "            test_mean[2], test_std[2],\n",
    "            \"Test\"\n",
    "            ]\n",
    "\n",
    "with open(name_file, 'a', newline='') as f:\n",
    "    csvwriter = csv.writer(f)\n",
    "    csvwriter.writerow(row_train)\n",
    "    csvwriter.writerow(row_test)\n",
    "    f.close()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\dra98\\OneDrive\\Documentos\\Trabajo\\Doctorado\\Codigo\\myvenv\\lib\\site-packages\\sklearn\\model_selection\\_split.py:700: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=5.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.45468242 0.52683282 0.56102502]\n",
      "[0.40625821 0.4548398  0.47542742]\n"
     ]
    }
   ],
   "source": [
    "# Classification Model\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "\n",
    "\n",
    "accuracies_tops_test = np.zeros((5,3))\n",
    "accuracies_tops_train = np.zeros((5,3))\n",
    "tops = (1, 3, 5)\n",
    "\n",
    "\n",
    "cross_validation = StratifiedKFold(n_splits = 5)\n",
    "\n",
    "X = data_matrix[:, :cfg.params.vector_length.sentence_embedding] \n",
    "y = data_matrix[:, cfg.params.vector_length.sentence_embedding+2]\n",
    "\n",
    "\n",
    "temp_test_acc = np.zeros(5)\n",
    "\n",
    "\n",
    "for c, (train_index, test_index) in enumerate(cross_validation.split(X, y)):\n",
    "\n",
    "    X_train = X[train_index, :]\n",
    "    y_train = y[train_index]\n",
    "\n",
    "    X_test = X[test_index, :]\n",
    "    y_test = y[test_index]\n",
    "\n",
    "\n",
    "    classification_model = DecisionTreeClassifier(max_leaf_nodes=1000, criterion='gini')\n",
    "\n",
    "    classification_model.fit(X_train, y_train)\n",
    "    pred = classification_model.predict_proba(X_test)\n",
    "\n",
    "    pred_ranking_test = set_labels(classification_model.predict_proba(X_test), classification_model.classes_)\n",
    "    pred_ranking_train = set_labels(classification_model.predict_proba(X_train), classification_model.classes_)\n",
    "    \n",
    "    top1_acc_test = np.zeros(len(y_test))\n",
    "    top3_acc_test = np.zeros(len(y_test))\n",
    "    top5_acc_test = np.zeros(len(y_test))\n",
    "\n",
    "    \n",
    "    for j in range(len(y_test)):\n",
    "        top1_acc_test[j] = int(y_test[j] in pred_ranking_test[j, :tops[0]])\n",
    "        top3_acc_test[j] = int(y_test[j] in pred_ranking_test[j, :tops[1]])\n",
    "        top5_acc_test[j] = int(y_test[j] in pred_ranking_test[j, :tops[2]])\n",
    "\n",
    "\n",
    "    accuracies_tops_test[c] = [np.mean(top1_acc_test), np.mean(top3_acc_test), np.mean(top5_acc_test)]\n",
    "\n",
    "\n",
    "\n",
    "    top1_acc_train = np.zeros(len(y_train))\n",
    "    top3_acc_train = np.zeros(len(y_train))\n",
    "    top5_acc_train = np.zeros(len(y_train))\n",
    "\n",
    "    \n",
    "    for j in range(len(y_train)):\n",
    "        top1_acc_train[j] = int(y_train[j] in pred_ranking_train[j, :tops[0]])\n",
    "        top3_acc_train[j] = int(y_train[j] in pred_ranking_train[j, :tops[1]])\n",
    "        top5_acc_train[j] = int(y_train[j] in pred_ranking_train[j, :tops[2]])\n",
    "    \n",
    "    accuracies_tops_train[c] = [np.mean(top1_acc_train), np.mean(top3_acc_train), np.mean(top5_acc_train)]\n",
    "    \n",
    "    # break\n",
    "\n",
    "print(accuracies_tops_train.mean(axis=0))\n",
    "print(accuracies_tops_test.mean(axis=0))\n",
    "\n",
    "train_mean = accuracies_tops_train.mean(axis=0)\n",
    "train_std = accuracies_tops_train.std(axis=0)\n",
    "\n",
    "row_train = [classification_model.__class__.__name__, \n",
    "            train_mean[0], train_std[0],\n",
    "            train_mean[1], train_std[1],\n",
    "            train_mean[2], train_std[2],\n",
    "            \"Train\"\n",
    "            ]\n",
    "\n",
    "test_mean = accuracies_tops_test.mean(axis=0)\n",
    "test_std = accuracies_tops_test.std(axis=0)\n",
    "\n",
    "row_test = [classification_model.__class__.__name__, \n",
    "            test_mean[0], test_std[0],\n",
    "            test_mean[1], test_std[1],\n",
    "            test_mean[2], test_std[2],\n",
    "            \"Test\"\n",
    "            ]\n",
    "\n",
    "with open(name_file, 'a', newline='') as f:\n",
    "    csvwriter = csv.writer(f)\n",
    "    csvwriter.writerow(row_train)\n",
    "    csvwriter.writerow(row_test)\n",
    "    f.close()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\dra98\\OneDrive\\Documentos\\Trabajo\\Doctorado\\Codigo\\myvenv\\lib\\site-packages\\sklearn\\model_selection\\_split.py:700: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=5.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.58784198 0.7508551  0.80237879]\n",
      "[0.51123566 0.66027533 0.71375256]\n"
     ]
    }
   ],
   "source": [
    "# Classification Model\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "\n",
    "\n",
    "accuracies_tops_test = np.zeros((5,3))\n",
    "accuracies_tops_train = np.zeros((5,3))\n",
    "tops = (1, 3, 5)\n",
    "\n",
    "\n",
    "cross_validation = StratifiedKFold(n_splits = 5)\n",
    "\n",
    "X = data_matrix[:, :cfg.params.vector_length.sentence_embedding] \n",
    "y = data_matrix[:, cfg.params.vector_length.sentence_embedding+2]\n",
    "\n",
    "\n",
    "temp_test_acc = np.zeros(5)\n",
    "\n",
    "\n",
    "for c, (train_index, test_index) in enumerate(cross_validation.split(X, y)):\n",
    "\n",
    "    X_train = X[train_index, :]\n",
    "    y_train = y[train_index]\n",
    "\n",
    "    X_test = X[test_index, :]\n",
    "    y_test = y[test_index]\n",
    "\n",
    "\n",
    "    classification_model = SVC(kernel='linear', C=1, probability=True)\n",
    "\n",
    "    classification_model.fit(X_train, y_train)\n",
    "    pred = classification_model.predict_proba(X_test)\n",
    "\n",
    "    pred_ranking_test = set_labels(classification_model.predict_proba(X_test), classification_model.classes_)\n",
    "    pred_ranking_train = set_labels(classification_model.predict_proba(X_train), classification_model.classes_)\n",
    "    \n",
    "    top1_acc_test = np.zeros(len(y_test))\n",
    "    top3_acc_test = np.zeros(len(y_test))\n",
    "    top5_acc_test = np.zeros(len(y_test))\n",
    "\n",
    "    \n",
    "    for j in range(len(y_test)):\n",
    "        top1_acc_test[j] = int(y_test[j] in pred_ranking_test[j, :tops[0]])\n",
    "        top3_acc_test[j] = int(y_test[j] in pred_ranking_test[j, :tops[1]])\n",
    "        top5_acc_test[j] = int(y_test[j] in pred_ranking_test[j, :tops[2]])\n",
    "\n",
    "\n",
    "    accuracies_tops_test[c] = [np.mean(top1_acc_test), np.mean(top3_acc_test), np.mean(top5_acc_test)]\n",
    "\n",
    "\n",
    "\n",
    "    top1_acc_train = np.zeros(len(y_train))\n",
    "    top3_acc_train = np.zeros(len(y_train))\n",
    "    top5_acc_train = np.zeros(len(y_train))\n",
    "\n",
    "    \n",
    "    for j in range(len(y_train)):\n",
    "        top1_acc_train[j] = int(y_train[j] in pred_ranking_train[j, :tops[0]])\n",
    "        top3_acc_train[j] = int(y_train[j] in pred_ranking_train[j, :tops[1]])\n",
    "        top5_acc_train[j] = int(y_train[j] in pred_ranking_train[j, :tops[2]])\n",
    "    \n",
    "    accuracies_tops_train[c] = [np.mean(top1_acc_train), np.mean(top3_acc_train), np.mean(top5_acc_train)]\n",
    "    \n",
    "    # break\n",
    "\n",
    "print(accuracies_tops_train.mean(axis=0))\n",
    "print(accuracies_tops_test.mean(axis=0))\n",
    "\n",
    "train_mean = accuracies_tops_train.mean(axis=0)\n",
    "train_std = accuracies_tops_train.std(axis=0)\n",
    "\n",
    "row_train = [classification_model.__class__.__name__, \n",
    "            train_mean[0], train_std[0],\n",
    "            train_mean[1], train_std[1],\n",
    "            train_mean[2], train_std[2],\n",
    "            \"Train\"\n",
    "            ]\n",
    "\n",
    "test_mean = accuracies_tops_test.mean(axis=0)\n",
    "test_std = accuracies_tops_test.std(axis=0)\n",
    "\n",
    "row_test = [classification_model.__class__.__name__, \n",
    "            test_mean[0], test_std[0],\n",
    "            test_mean[1], test_std[1],\n",
    "            test_mean[2], test_std[2],\n",
    "            \"Test\"\n",
    "            ]\n",
    "\n",
    "with open(name_file, 'a', newline='') as f:\n",
    "    csvwriter = csv.writer(f)\n",
    "    csvwriter.writerow(row_train)\n",
    "    csvwriter.writerow(row_test)\n",
    "    f.close()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "cod = pd.DataFrame(data_matrix).iloc[:,cfg.params.vector_length.sentence_embedding+2].value_counts()\n",
    "reduce_cod = cod[cod<5]\n",
    "n=5\n",
    "data_fill = pd.DataFrame(data_matrix).copy()\n",
    "\n",
    "for key, value in reduce_cod.items():\n",
    "    m=np.abs(n-value)\n",
    "    nrow = np.zeros(cfg.params.vector_length.sentence_embedding)\n",
    "    nrow = np.concatenate([nrow, np.array(['', '', key])])\n",
    "    for i in range(m): data_fill = np.vstack([data_fill,nrow])\n",
    "\n",
    "\n",
    "y = data_fill[:, cfg.params.vector_length.sentence_embedding+2]\n",
    "\n",
    "labels = np.unique(y)\n",
    "i=0\n",
    "idx2class = {}\n",
    "class2idx= {}\n",
    "for tp in labels:\n",
    "    idx2class[i] = tp\n",
    "    class2idx[tp] = i\n",
    "    i += 1\n",
    "\n",
    "y_label = np.vectorize(class2idx.get)(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.37968489 0.4211622  0.43486993]\n",
      "[0.31296102 0.3421471  0.35471862]\n"
     ]
    }
   ],
   "source": [
    "# Classification Model\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "accuracies_tops_test = np.zeros((5,3))\n",
    "accuracies_tops_train = np.zeros((5,3))\n",
    "tops = (1, 3, 5)\n",
    "\n",
    "\n",
    "cross_validation = StratifiedKFold(n_splits = 5)\n",
    "\n",
    "X = data_fill[:, :cfg.params.vector_length.sentence_embedding]\n",
    "y = y_label\n",
    "\n",
    "temp_test_acc = np.zeros(5)\n",
    "\n",
    "\n",
    "for c, (train_index, test_index) in enumerate(cross_validation.split(X, y)):\n",
    "\n",
    "    X_train = X[train_index, :]\n",
    "    y_train = y[train_index]\n",
    "\n",
    "    X_test = X[test_index, :]\n",
    "    y_test = y[test_index]\n",
    "\n",
    "\n",
    "    classification_model = RandomForestClassifier(random_state=0, max_depth=10)\n",
    "\n",
    "    classification_model.fit(X_train, y_train)\n",
    "    pred = classification_model.predict_proba(X_test)\n",
    "\n",
    "    pred_ranking_test = set_labels(classification_model.predict_proba(X_test), classification_model.classes_)\n",
    "    pred_ranking_train = set_labels(classification_model.predict_proba(X_train), classification_model.classes_)\n",
    "    \n",
    "    top1_acc_test = np.zeros(len(y_test))\n",
    "    top3_acc_test = np.zeros(len(y_test))\n",
    "    top5_acc_test = np.zeros(len(y_test))\n",
    "\n",
    "    \n",
    "    for j in range(len(y_test)):\n",
    "        top1_acc_test[j] = int(y_test[j] in pred_ranking_test[j, :tops[0]])\n",
    "        top3_acc_test[j] = int(y_test[j] in pred_ranking_test[j, :tops[1]])\n",
    "        top5_acc_test[j] = int(y_test[j] in pred_ranking_test[j, :tops[2]])\n",
    "\n",
    "\n",
    "    accuracies_tops_test[c] = [np.mean(top1_acc_test), np.mean(top3_acc_test), np.mean(top5_acc_test)]\n",
    "\n",
    "\n",
    "\n",
    "    top1_acc_train = np.zeros(len(y_train))\n",
    "    top3_acc_train = np.zeros(len(y_train))\n",
    "    top5_acc_train = np.zeros(len(y_train))\n",
    "\n",
    "    \n",
    "    for j in range(len(y_train)):\n",
    "        top1_acc_train[j] = int(y_train[j] in pred_ranking_train[j, :tops[0]])\n",
    "        top3_acc_train[j] = int(y_train[j] in pred_ranking_train[j, :tops[1]])\n",
    "        top5_acc_train[j] = int(y_train[j] in pred_ranking_train[j, :tops[2]])\n",
    "    \n",
    "    accuracies_tops_train[c] = [np.mean(top1_acc_train), np.mean(top3_acc_train), np.mean(top5_acc_train)]\n",
    "    \n",
    "    # break\n",
    "\n",
    "print(accuracies_tops_train.mean(axis=0))\n",
    "print(accuracies_tops_test.mean(axis=0))\n",
    "\n",
    "train_mean = accuracies_tops_train.mean(axis=0)\n",
    "train_std = accuracies_tops_train.std(axis=0)\n",
    "\n",
    "row_train = [classification_model.__class__.__name__, \n",
    "            train_mean[0], train_std[0],\n",
    "            train_mean[1], train_std[1],\n",
    "            train_mean[2], train_std[2],\n",
    "            \"Train\"\n",
    "            ]\n",
    "\n",
    "test_mean = accuracies_tops_test.mean(axis=0)\n",
    "test_std = accuracies_tops_test.std(axis=0)\n",
    "\n",
    "row_test = [classification_model.__class__.__name__, \n",
    "            test_mean[0], test_std[0],\n",
    "            test_mean[1], test_std[1],\n",
    "            test_mean[2], test_std[2],\n",
    "            \"Test\"\n",
    "            ]\n",
    "\n",
    "with open(name_file, 'a', newline='') as f:\n",
    "    csvwriter = csv.writer(f)\n",
    "    csvwriter.writerow(row_train)\n",
    "    csvwriter.writerow(row_test)\n",
    "    f.close()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.26471793 0.27550405 0.2800487 ]\n",
      "[0.20746202 0.22587687 0.23419885]\n"
     ]
    }
   ],
   "source": [
    "# Classification Model\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "\n",
    "\n",
    "accuracies_tops_test = np.zeros((5,3))\n",
    "accuracies_tops_train = np.zeros((5,3))\n",
    "tops = (1, 3, 5)\n",
    "\n",
    "\n",
    "cross_validation = StratifiedKFold(n_splits = 5)\n",
    "\n",
    "X = data_fill[:, :cfg.params.vector_length.sentence_embedding]\n",
    "y = y_label\n",
    "\n",
    "temp_test_acc = np.zeros(5)\n",
    "\n",
    "\n",
    "for c, (train_index, test_index) in enumerate(cross_validation.split(X, y)):\n",
    "\n",
    "    X_train = X[train_index, :]\n",
    "    y_train = y[train_index]\n",
    "\n",
    "    X_test = X[test_index, :]\n",
    "    y_test = y[test_index]\n",
    "\n",
    "\n",
    "    classification_model = XGBClassifier(learning_rate=1, objective='multi:softprob', random_state=0, max_depth=50, n_estimators=15)\n",
    "\n",
    "    classification_model.fit(X_train, y_train)\n",
    "    pred = classification_model.predict_proba(X_test)\n",
    "\n",
    "    pred_ranking_test = set_labels(classification_model.predict_proba(X_test), classification_model.classes_)\n",
    "    pred_ranking_train = set_labels(classification_model.predict_proba(X_train), classification_model.classes_)\n",
    "    \n",
    "    top1_acc_test = np.zeros(len(y_test))\n",
    "    top3_acc_test = np.zeros(len(y_test))\n",
    "    top5_acc_test = np.zeros(len(y_test))\n",
    "\n",
    "    \n",
    "    for j in range(len(y_test)):\n",
    "        top1_acc_test[j] = int(y_test[j] in pred_ranking_test[j, :tops[0]])\n",
    "        top3_acc_test[j] = int(y_test[j] in pred_ranking_test[j, :tops[1]])\n",
    "        top5_acc_test[j] = int(y_test[j] in pred_ranking_test[j, :tops[2]])\n",
    "\n",
    "\n",
    "    accuracies_tops_test[c] = [np.mean(top1_acc_test), np.mean(top3_acc_test), np.mean(top5_acc_test)]\n",
    "\n",
    "\n",
    "\n",
    "    top1_acc_train = np.zeros(len(y_train))\n",
    "    top3_acc_train = np.zeros(len(y_train))\n",
    "    top5_acc_train = np.zeros(len(y_train))\n",
    "\n",
    "    \n",
    "    for j in range(len(y_train)):\n",
    "        top1_acc_train[j] = int(y_train[j] in pred_ranking_train[j, :tops[0]])\n",
    "        top3_acc_train[j] = int(y_train[j] in pred_ranking_train[j, :tops[1]])\n",
    "        top5_acc_train[j] = int(y_train[j] in pred_ranking_train[j, :tops[2]])\n",
    "    \n",
    "    accuracies_tops_train[c] = [np.mean(top1_acc_train), np.mean(top3_acc_train), np.mean(top5_acc_train)]\n",
    "    \n",
    "    # break\n",
    "\n",
    "print(accuracies_tops_train.mean(axis=0))\n",
    "print(accuracies_tops_test.mean(axis=0))\n",
    "\n",
    "train_mean = accuracies_tops_train.mean(axis=0)\n",
    "train_std = accuracies_tops_train.std(axis=0)\n",
    "\n",
    "row_train = [classification_model.__class__.__name__, \n",
    "            train_mean[0], train_std[0],\n",
    "            train_mean[1], train_std[1],\n",
    "            train_mean[2], train_std[2],\n",
    "            \"Train\"\n",
    "            ]\n",
    "\n",
    "test_mean = accuracies_tops_test.mean(axis=0)\n",
    "test_std = accuracies_tops_test.std(axis=0)\n",
    "\n",
    "row_test = [classification_model.__class__.__name__, \n",
    "            test_mean[0], test_std[0],\n",
    "            test_mean[1], test_std[1],\n",
    "            test_mean[2], test_std[2],\n",
    "            \"Test\"\n",
    "            ]\n",
    "\n",
    "with open(name_file, 'a', newline='') as f:\n",
    "    csvwriter = csv.writer(f)\n",
    "    csvwriter.writerow(row_train)\n",
    "    csvwriter.writerow(row_test)\n",
    "    f.close()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myvenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
