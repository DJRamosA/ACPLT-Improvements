{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "import time\n",
    "from scipy.stats import mode\n",
    "import sys\n",
    "import os\n",
    "\n",
    "# Canine Embedding\n",
    "from transformers import CanineTokenizer, CanineModel\n",
    "\n",
    "\n",
    "random.seed(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vector_length = 768\n",
    "\n",
    "model = CanineModel.from_pretrained('google/canine-s')\n",
    "tokenizer = CanineTokenizer.from_pretrained('google/canine-s')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"CPN27_lemma.csv\", delimiter=\",\")\n",
    "data = data.fillna(value='')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Timer\n",
    "start = time.time()\n",
    "\n",
    "descriptions_matrix = np.zeros( # creatign an empty matrix\n",
    "    (\n",
    "        len(data.iloc[:,1]),                                # the number of data points\n",
    "        vector_length        # the number of components of the word embedding\n",
    "    )\n",
    ")\n",
    "\n",
    "for i,description in enumerate(data.iloc[:,1]):\n",
    "    vector = model(**tokenizer(description, padding=\"max_length\", truncation=True, return_tensors=\"pt\")).pooler_output.detach().numpy()[0]\n",
    "    descriptions_matrix[i,] = vector\n",
    "# Concatenate the matrix with the data of each observation\n",
    "\n",
    "data_matrix = np.concatenate([descriptions_matrix,data.iloc[:,:]], axis=1)\n",
    "\n",
    "\n",
    "# Remove of the 'Nan' data\n",
    "data_matrix = data_matrix[~pd.isnull(data_matrix[:,:vector_length]).any(axis=1)]\n",
    "\n",
    "\n",
    "end = time.time()\n",
    "print(\"Execution time:\", end-start)\n",
    "\n",
    "pd.DataFrame(data_matrix).to_csv(\"cpn27_lemma_canine_raw.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"CPN120_lemma.csv\", delimiter=\",\")\n",
    "data = data.fillna(value='')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start = time.time()\n",
    "\n",
    "descriptions_matrix = np.zeros( # creatign an empty matrix\n",
    "    (\n",
    "        len(data.iloc[:,1]),                                # the number of data points\n",
    "        vector_length         # the number of components of the word embedding\n",
    "    )\n",
    ")\n",
    "\n",
    "for i,description in enumerate(data.iloc[:,1]):\n",
    "    vector = model(**tokenizer(description, padding=\"max_length\", truncation=True, return_tensors=\"pt\")).pooler_output.detach().numpy()[0]\n",
    "    descriptions_matrix[i,] = vector\n",
    "# Concatenate the matrix with the data of each observation\n",
    "\n",
    "data_matrix = np.concatenate([descriptions_matrix,data.iloc[:,:]], axis=1)\n",
    "\n",
    "\n",
    "# Remove of the 'Nan' data\n",
    "data_matrix = data_matrix[~pd.isnull(data_matrix[:,:vector_length]).any(axis=1)]\n",
    "\n",
    "\n",
    "end = time.time()\n",
    "print(\"Execution time:\", end-start)\n",
    "\n",
    "pd.DataFrame(data_matrix).to_csv(\"cpn120_lemma_canine_raw.csv\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
